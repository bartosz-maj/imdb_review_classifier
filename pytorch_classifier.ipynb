{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!mv ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "TEH4AuDdQynz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import torch.utils.data as data_utils\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "eqoADU-EBobX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d bartoszmaj/tfidf-imdb-20k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2Xa2BZBKOow",
        "outputId": "f48da610-683e-4054-9d07-5d64ae34891d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading tfidf-imdb-20k.zip to /content\n",
            "100% 0.99G/0.99G [00:56<00:00, 18.5MB/s]\n",
            "100% 0.99G/0.99G [00:56<00:00, 19.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip tfidf-imdb-20k.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PU92pA8jKge5",
        "outputId": "72e8fd0f-9f5a-4ee8-8e5b-8058018a785f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  tfidf-imdb-20k.zip\n",
            "  inflating: X_test.csv              \n",
            "  inflating: X_train.csv             \n",
            "  inflating: y_test.csv              \n",
            "  inflating: y_train.csv             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d bartoszmaj/x-test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kc3IadJrLXAK",
        "outputId": "171b3bc5-858f-476e-e6f6-d8f923d8ca53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading x-test.zip to /content\n",
            " 99% 674M/678M [00:05<00:00, 154MB/s]\n",
            "100% 678M/678M [00:05<00:00, 127MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip x-test.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nraMKVdSLY3i",
        "outputId": "1f8f7330-fd8b-4583-c33f-c2be2547e4e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  x-test.zip\n",
            "  inflating: X_test.csv              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pd.read_csv(\"X_train.csv\")\n",
        "X_test = pd.read_csv(\"X_test.csv\")\n"
      ],
      "metadata": {
        "id": "WGNLdzTpBz8M"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = pd.read_csv(\"y_train.csv\")\n",
        "y_test = pd.read_csv(\"y_test.csv\")"
      ],
      "metadata": {
        "id": "37HCiOs5UXDh"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32"
      ],
      "metadata": {
        "id": "0nBDKHH_CSSO"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.replace(\"negative\", 0)\n",
        "y_train = y_train.replace(\"positive\", 1)\n",
        "y_test = y_test.replace(\"negative\", 0)\n",
        "y_test = y_test.replace(\"positive\", 1)\n",
        "y_train.head(), y_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHrhxD47PHFJ",
        "outputId": "2bd606d2-a15f-4cbd-8781-28996d39bf63"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(   sentiment\n",
              " 0          0\n",
              " 1          1\n",
              " 2          0\n",
              " 3          1\n",
              " 4          0,\n",
              "    sentiment\n",
              " 0          1\n",
              " 1          1\n",
              " 2          0\n",
              " 3          1\n",
              " 4          0)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "acYsiSl8Aypa"
      },
      "outputs": [],
      "source": [
        "train_target = torch.tensor(y_train.values.astype(np.float32))\n",
        "train_target = train_target.flatten()\n",
        "train = torch.tensor(X_train.values.astype(np.float32)) \n",
        "train_tensor = data_utils.TensorDataset(train, train_target) \n",
        "train_loader = data_utils.DataLoader(dataset = train_tensor, batch_size = batch_size, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_target = torch.tensor(y_test.values.astype(np.float32))\n",
        "test_target = test_target.flatten()\n",
        "test = torch.tensor(X_test.values.astype(np.float32)) \n",
        "test_tensor = data_utils.TensorDataset(test, test_target) \n",
        "test_loader = data_utils.DataLoader(dataset = test_tensor, batch_size = batch_size, shuffle = True)"
      ],
      "metadata": {
        "id": "-DyGvXY4CKfc"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available(): \n",
        " dev = \"cuda:0\" \n",
        "else: \n",
        " dev = \"cpu\" \n",
        "device = torch.device(dev) "
      ],
      "metadata": {
        "id": "hMiAH9vnQ8AL"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(2500, 500)\n",
        "    self.fc2 = nn.Linear(500, 2)\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x \n",
        "  \n",
        "net = Net().to(device)"
      ],
      "metadata": {
        "id": "nZFoTCONPwK7"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.0001\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr = lr)"
      ],
      "metadata": {
        "id": "W_z6tLLfRTiz"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 25\n",
        "for epoch in range(epochs):\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    inputs, labels = data\n",
        "    labels = labels.type(torch.LongTensor)\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = net(inputs)\n",
        "    loss = loss_func(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  train_correct = 0\n",
        "  train_total = 0\n",
        "  with torch.no_grad():\n",
        "    for train_data in train_loader:\n",
        "      train_inputs, train_labels = train_data\n",
        "      train_inputs = train_inputs.to(dev)\n",
        "      train_labels = train_labels.to(dev)\n",
        "\n",
        "      train_outputs = net(train_inputs)\n",
        "      _, predicted = torch.max(train_outputs.data, 1)\n",
        "      train_total += train_labels.size(0)\n",
        "      train_correct += (predicted == train_labels).sum().item()\n",
        "  print(f'Epoch: {epoch}')\n",
        "  print(f'Training accuracy: {100 * train_correct // train_total} %')\n",
        "\n",
        "  test_total = 0\n",
        "  test_correct = 0 \n",
        "  net.eval()\n",
        "  with torch.no_grad():\n",
        "    for test_data in test_loader:\n",
        "      test_inputs, test_labels = test_data\n",
        "      test_inputs = test_inputs.to(dev)\n",
        "      test_labels = test_labels.to(dev)\n",
        "\n",
        "      test_outputs = net(test_inputs)\n",
        "      _, predicted = torch.max(test_outputs.data, 1)\n",
        "      test_total += test_inputs.size(0)\n",
        "      test_correct += (predicted == test_labels).sum().item()\n",
        "  print(f'Testing accuracy: {100 * test_correct // test_total} %')\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "8ECPjhWsRiqZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28134b79-9c3d-41e0-9256-eff1fc746542"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "Training accuracy: 86 %\n",
            "Testing accuracy: 86 %\n",
            "Epoch: 1\n",
            "Training accuracy: 88 %\n",
            "Testing accuracy: 88 %\n",
            "Epoch: 2\n",
            "Training accuracy: 90 %\n",
            "Testing accuracy: 89 %\n",
            "Epoch: 3\n",
            "Training accuracy: 90 %\n",
            "Testing accuracy: 89 %\n",
            "Epoch: 4\n",
            "Training accuracy: 91 %\n",
            "Testing accuracy: 89 %\n",
            "Epoch: 5\n",
            "Training accuracy: 91 %\n",
            "Testing accuracy: 89 %\n",
            "Epoch: 6\n",
            "Training accuracy: 91 %\n",
            "Testing accuracy: 89 %\n",
            "Epoch: 7\n",
            "Training accuracy: 91 %\n",
            "Testing accuracy: 89 %\n",
            "Epoch: 8\n",
            "Training accuracy: 92 %\n",
            "Testing accuracy: 89 %\n",
            "Epoch: 9\n",
            "Training accuracy: 92 %\n",
            "Testing accuracy: 90 %\n",
            "Epoch: 10\n",
            "Training accuracy: 92 %\n",
            "Testing accuracy: 89 %\n",
            "Epoch: 11\n",
            "Training accuracy: 92 %\n",
            "Testing accuracy: 90 %\n",
            "Epoch: 12\n",
            "Training accuracy: 92 %\n",
            "Testing accuracy: 90 %\n",
            "Epoch: 13\n",
            "Training accuracy: 92 %\n",
            "Testing accuracy: 89 %\n",
            "Epoch: 14\n",
            "Training accuracy: 92 %\n",
            "Testing accuracy: 89 %\n",
            "Epoch: 15\n",
            "Training accuracy: 93 %\n",
            "Testing accuracy: 90 %\n",
            "Epoch: 16\n",
            "Training accuracy: 93 %\n",
            "Testing accuracy: 90 %\n",
            "Epoch: 17\n",
            "Training accuracy: 93 %\n",
            "Testing accuracy: 90 %\n",
            "Epoch: 18\n",
            "Training accuracy: 93 %\n",
            "Testing accuracy: 90 %\n",
            "Epoch: 19\n",
            "Training accuracy: 94 %\n",
            "Testing accuracy: 90 %\n",
            "Epoch: 20\n",
            "Training accuracy: 94 %\n",
            "Testing accuracy: 90 %\n",
            "Epoch: 21\n",
            "Training accuracy: 94 %\n",
            "Testing accuracy: 89 %\n",
            "Epoch: 22\n",
            "Training accuracy: 95 %\n",
            "Testing accuracy: 90 %\n",
            "Epoch: 23\n",
            "Training accuracy: 95 %\n",
            "Testing accuracy: 90 %\n",
            "Epoch: 24\n",
            "Training accuracy: 95 %\n",
            "Testing accuracy: 90 %\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CIdAZsXzicEG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}