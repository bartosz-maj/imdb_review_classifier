{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEXFP1ph7lwF",
        "outputId": "8a508d48-194a-4b6a-b1b3-b6749222ffc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in c:\\users\\bmaj3\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.3.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\bmaj3\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gensim) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\bmaj3\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gensim) (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\bmaj3\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gensim) (6.3.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "w-FY5hlD7ose"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.decomposition import TruncatedSVD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DcAL403W7tzT"
      },
      "outputs": [],
      "source": [
        "text = pd.read_csv(\"IMDB Dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UmC8CvNJ8qGk",
        "outputId": "1546baac-4e79-44fd-edf8-f4961b1f48f9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1XY94pq09N7M",
        "outputId": "7e414b74-19cc-4262-e01f-992d1efb4fb9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>[one, of, the, other, reviewers, has, mentione...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "      <td>[wonderful, little, production, br, br, the, f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "      <td>[thought, this, was, wonderful, way, to, spend...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[basically, there, family, where, little, boy,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "      <td>[petter, mattei, love, in, the, time, of, mone...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment  \\\n",
              "0  One of the other reviewers has mentioned that ...  positive   \n",
              "1  A wonderful little production. <br /><br />The...  positive   \n",
              "2  I thought this was a wonderful way to spend ti...  positive   \n",
              "3  Basically there's a family where a little boy ...  negative   \n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
              "\n",
              "                                        review_clean  \n",
              "0  [one, of, the, other, reviewers, has, mentione...  \n",
              "1  [wonderful, little, production, br, br, the, f...  \n",
              "2  [thought, this, was, wonderful, way, to, spend...  \n",
              "3  [basically, there, family, where, little, boy,...  \n",
              "4  [petter, mattei, love, in, the, time, of, mone...  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text[\"review_clean\"] = text[\"review\"].apply(lambda x: gensim.utils.simple_preprocess(x))\n",
        "text.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mFa6JLi89e8z"
      },
      "outputs": [],
      "source": [
        "clean_text = text[[\"review_clean\"]]\n",
        "labels = text[\"sentiment\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wfQ884eLuh7",
        "outputId": "aebf39c6-ab0a-49e3-e198-b7f553ddab79"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "71moLCX6I5q9"
      },
      "outputs": [],
      "source": [
        "corpus = []\n",
        "for review in clean_text[\"review_clean\"]:\n",
        "  corpus.append(\" \".join(review))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJ0o4p0eLE3b",
        "outputId": "076c1a00-39eb-4dcf-ffe5-9c2e05ad4bf3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqW0SzBVLtIo",
        "outputId": "5606b6c0-5a17-4a0e-8717-30722c3f6b5c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\bmaj3\\AppData\\Local\\Temp\\ipykernel_6160\\1042297266.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  clean_text[\"corpus\"] = corpus\n"
          ]
        }
      ],
      "source": [
        "clean_text[\"corpus\"] = corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTbQx2pbL_Ec",
        "outputId": "1e340df7-b101-4c55-ba0f-303c6c2c0247"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "_ULo3isJMB1f",
        "outputId": "6f10d5e4-f652-4ad0-b090-deddfb19ea8e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_clean</th>\n",
              "      <th>corpus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[one, of, the, other, reviewers, has, mentione...</td>\n",
              "      <td>one of the other reviewers has mentioned that ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[wonderful, little, production, br, br, the, f...</td>\n",
              "      <td>wonderful little production br br the filming ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[thought, this, was, wonderful, way, to, spend...</td>\n",
              "      <td>thought this was wonderful way to spend time o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[basically, there, family, where, little, boy,...</td>\n",
              "      <td>basically there family where little boy jake t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[petter, mattei, love, in, the, time, of, mone...</td>\n",
              "      <td>petter mattei love in the time of money is vis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>[thought, this, movie, did, down, right, good,...</td>\n",
              "      <td>thought this movie did down right good job it ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>[bad, plot, bad, dialogue, bad, acting, idioti...</td>\n",
              "      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>[am, catholic, taught, in, parochial, elementa...</td>\n",
              "      <td>am catholic taught in parochial elementary sch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>[going, to, have, to, disagree, with, the, pre...</td>\n",
              "      <td>going to have to disagree with the previous co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>[no, one, expects, the, star, trek, movies, to...</td>\n",
              "      <td>no one expects the star trek movies to be high...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            review_clean  \\\n",
              "0      [one, of, the, other, reviewers, has, mentione...   \n",
              "1      [wonderful, little, production, br, br, the, f...   \n",
              "2      [thought, this, was, wonderful, way, to, spend...   \n",
              "3      [basically, there, family, where, little, boy,...   \n",
              "4      [petter, mattei, love, in, the, time, of, mone...   \n",
              "...                                                  ...   \n",
              "49995  [thought, this, movie, did, down, right, good,...   \n",
              "49996  [bad, plot, bad, dialogue, bad, acting, idioti...   \n",
              "49997  [am, catholic, taught, in, parochial, elementa...   \n",
              "49998  [going, to, have, to, disagree, with, the, pre...   \n",
              "49999  [no, one, expects, the, star, trek, movies, to...   \n",
              "\n",
              "                                                  corpus  \n",
              "0      one of the other reviewers has mentioned that ...  \n",
              "1      wonderful little production br br the filming ...  \n",
              "2      thought this was wonderful way to spend time o...  \n",
              "3      basically there family where little boy jake t...  \n",
              "4      petter mattei love in the time of money is vis...  \n",
              "...                                                  ...  \n",
              "49995  thought this movie did down right good job it ...  \n",
              "49996  bad plot bad dialogue bad acting idiotic direc...  \n",
              "49997  am catholic taught in parochial elementary sch...  \n",
              "49998  going to have to disagree with the previous co...  \n",
              "49999  no one expects the star trek movies to be high...  \n",
              "\n",
              "[50000 rows x 2 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ml7DQjhYBf7k"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(clean_text, \n",
        "                                                    labels, \n",
        "                                                    test_size=0.30, \n",
        "                                                    random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "sVgKX5y3KNlD"
      },
      "outputs": [],
      "source": [
        "tfidf_vect = TfidfVectorizer(max_features = 20000, ngram_range = (1,2) )\n",
        "X_train_tfidf = tfidf_vect.fit_transform(X_train[\"corpus\"])\n",
        "X_test_tfidf = tfidf_vect.transform(X_test[\"corpus\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "z2ryaYZeZLZG"
      },
      "outputs": [],
      "source": [
        "svd = TruncatedSVD(n_components = 2000, n_iter=7, random_state=42)\n",
        "X_train_reduced = svd.fit_transform(X_train_tfidf)\n",
        "X_test_reduced = svd.transform(X_test_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.4523164557189412\n"
          ]
        }
      ],
      "source": [
        "print(sum(svd.explained_variance_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "0nROyGJRPWLb"
      },
      "outputs": [],
      "source": [
        "X_train_tfidf_df = pd.DataFrame(X_train_reduced, index = X_train.index, columns = [i for i in range(501, 2501)])\n",
        "X_test_tfidf_df = pd.DataFrame(X_test_reduced, index = X_test.index, columns = [i for i in range(501, 2501)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "gJ4pJR0KBtcZ"
      },
      "outputs": [],
      "source": [
        "w2v_model = gensim.models.Word2Vec(X_train[\"review_clean\"],\n",
        "                                   vector_size=500,\n",
        "                                   window=5,\n",
        "                                   min_count=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "m1oxYI9VB4R7"
      },
      "outputs": [
        {
          "ename": "MemoryError",
          "evalue": "Unable to allocate 854. KiB for an array with shape (437, 500) and data type float32",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\bmaj3\\Desktop\\imdb_class\\bigram_extraction.ipynb Cell 19\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bmaj3/Desktop/imdb_class/bigram_extraction.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m words \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(w2v_model\u001b[39m.\u001b[39mwv\u001b[39m.\u001b[39mindex_to_key)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/bmaj3/Desktop/imdb_class/bigram_extraction.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m X_train_vect \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marray([w2v_model\u001b[39m.\u001b[39mwv[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m ls \u001b[39mif\u001b[39;00m i \u001b[39min\u001b[39;00m words]) \u001b[39mfor\u001b[39;00m ls \u001b[39min\u001b[39;00m X_train[\u001b[39m\"\u001b[39m\u001b[39mreview_clean\u001b[39m\u001b[39m\"\u001b[39m]], dtype \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bmaj3/Desktop/imdb_class/bigram_extraction.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m X_test_vect \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marray([w2v_model\u001b[39m.\u001b[39mwv[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m ls \u001b[39mif\u001b[39;00m i \u001b[39min\u001b[39;00m words]) \u001b[39mfor\u001b[39;00m ls \u001b[39min\u001b[39;00m X_test[\u001b[39m\"\u001b[39m\u001b[39mreview_clean\u001b[39m\u001b[39m\"\u001b[39m]], dtype \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;32mc:\\Users\\bmaj3\\Desktop\\imdb_class\\bigram_extraction.ipynb Cell 19\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bmaj3/Desktop/imdb_class/bigram_extraction.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m words \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(w2v_model\u001b[39m.\u001b[39mwv\u001b[39m.\u001b[39mindex_to_key)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/bmaj3/Desktop/imdb_class/bigram_extraction.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m X_train_vect \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39;49marray([w2v_model\u001b[39m.\u001b[39;49mwv[i] \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m ls \u001b[39mif\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m words]) \u001b[39mfor\u001b[39;00m ls \u001b[39min\u001b[39;00m X_train[\u001b[39m\"\u001b[39m\u001b[39mreview_clean\u001b[39m\u001b[39m\"\u001b[39m]], dtype \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bmaj3/Desktop/imdb_class/bigram_extraction.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m X_test_vect \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marray([w2v_model\u001b[39m.\u001b[39mwv[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m ls \u001b[39mif\u001b[39;00m i \u001b[39min\u001b[39;00m words]) \u001b[39mfor\u001b[39;00m ls \u001b[39min\u001b[39;00m X_test[\u001b[39m\"\u001b[39m\u001b[39mreview_clean\u001b[39m\u001b[39m\"\u001b[39m]], dtype \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 854. KiB for an array with shape (437, 500) and data type float32"
          ]
        }
      ],
      "source": [
        "words = set(w2v_model.wv.index_to_key)\n",
        "X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words]) for ls in X_train[\"review_clean\"]], dtype = \"object\")\n",
        "X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words]) for ls in X_test[\"review_clean\"]], dtype = \"object\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yATe902ELz6"
      },
      "outputs": [],
      "source": [
        "# Compute sentence vectors by averaging the word vectors for the words contained in the sentence\n",
        "X_train_vect_avg = []\n",
        "for v in X_train_vect:\n",
        "    if v.size:\n",
        "        X_train_vect_avg.append(v.mean(axis=0))\n",
        "    else:\n",
        "        X_train_vect_avg.append(np.zeros(100, dtype=float))\n",
        "        \n",
        "X_test_vect_avg = []\n",
        "for v in X_test_vect:\n",
        "    if v.size:\n",
        "        X_test_vect_avg.append(v.mean(axis=0))\n",
        "    else:\n",
        "        X_test_vect_avg.append(np.zeros(100, dtype=float))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xFDc8hFI0T8"
      },
      "outputs": [],
      "source": [
        "X_train_df = pd.DataFrame(X_train_vect_avg, index = X_train.index)\n",
        "X_test_df = pd.DataFrame(X_test_vect_avg, index = X_test.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBpIx_hkeJ24"
      },
      "outputs": [],
      "source": [
        "X_train = pd.concat([X_train_df, X_train_tfidf_df], axis = 1)\n",
        "X_test = pd.concat([X_test_df, X_test_tfidf_df], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LbYhUo3eJ25"
      },
      "outputs": [],
      "source": [
        "X_train.to_csv(\"X_train.csv\",index = False)\n",
        "X_test.to_csv(\"X_test.csv\",index = False)\n",
        "y_train.to_csv(\"y_train.csv\", index = False)\n",
        "y_test.to_csv(\"y_test.csv\",index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SL2iN3FBIutm"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymbe7YP1eJ27"
      },
      "outputs": [],
      "source": [
        "mlp_clf = MLPClassifier(random_state=1, \n",
        "                        max_iter=300, \n",
        "                        verbose = True, \n",
        "                        learning_rate = \"adaptive\",\n",
        "                        hidden_layer_sizes= (500,))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ymzMbjleJ28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.38749930\n",
            "Iteration 2, loss = 0.24658916\n",
            "Iteration 3, loss = 0.21293549\n",
            "Iteration 4, loss = 0.19014922\n",
            "Iteration 5, loss = 0.18375236\n",
            "Iteration 6, loss = 0.17566792\n",
            "Iteration 7, loss = 0.17123731\n",
            "Iteration 8, loss = 0.15795378\n",
            "Iteration 9, loss = 0.14428965\n",
            "Iteration 10, loss = 0.13428781\n",
            "Iteration 11, loss = 0.12434926\n",
            "Iteration 12, loss = 0.10714290\n",
            "Iteration 13, loss = 0.09331174\n",
            "Iteration 14, loss = 0.07875423\n",
            "Iteration 15, loss = 0.06747858\n",
            "Iteration 16, loss = 0.05472088\n",
            "Iteration 17, loss = 0.04251535\n",
            "Iteration 18, loss = 0.03487007\n",
            "Iteration 19, loss = 0.02673709\n",
            "Iteration 20, loss = 0.02108592\n",
            "Iteration 21, loss = 0.01785871\n",
            "Iteration 22, loss = 0.01459899\n",
            "Iteration 23, loss = 0.01259750\n",
            "Iteration 24, loss = 0.01107103\n",
            "Iteration 25, loss = 0.00982784\n",
            "Iteration 26, loss = 0.00915641\n",
            "Iteration 27, loss = 0.00831672\n",
            "Iteration 28, loss = 0.00793759\n",
            "Iteration 29, loss = 0.00753967\n",
            "Iteration 30, loss = 0.00724232\n",
            "Iteration 31, loss = 0.00723625\n",
            "Iteration 32, loss = 0.00683685\n",
            "Iteration 33, loss = 0.00684559\n",
            "Iteration 34, loss = 0.00616529\n",
            "Iteration 35, loss = 0.00586670\n",
            "Iteration 36, loss = 0.00574581\n",
            "Iteration 37, loss = 0.00556967\n",
            "Iteration 38, loss = 0.00543493\n",
            "Iteration 39, loss = 0.00530517\n",
            "Iteration 40, loss = 0.00517365\n",
            "Iteration 41, loss = 0.00508136\n",
            "Iteration 42, loss = 0.00495521\n",
            "Iteration 43, loss = 0.00485418\n",
            "Iteration 44, loss = 0.00475820\n",
            "Iteration 45, loss = 0.00469594\n",
            "Iteration 46, loss = 0.06809047\n",
            "Iteration 47, loss = 0.02997722\n",
            "Iteration 48, loss = 0.01277895\n",
            "Iteration 49, loss = 0.00954284\n",
            "Iteration 50, loss = 0.00847449\n",
            "Iteration 51, loss = 0.00780906\n",
            "Iteration 52, loss = 0.00732613\n",
            "Iteration 53, loss = 0.00693942\n",
            "Iteration 54, loss = 0.00659824\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLPClassifier(hidden_layer_sizes=(500,), learning_rate='adaptive', max_iter=300,\n",
              "              random_state=1, verbose=True)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlp_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdCj4YpteJ29"
      },
      "outputs": [],
      "source": [
        "y_predict = mlp_clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpURHzNkeJ29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8988666666666667\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_score(y_test, y_predict))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "tfidf - 20,000 max features, unigrams and bigrams. SVD reduction to 2000 features, over 7 iterations. \n",
        "word2vec - 300 length vectors, averaged. \n",
        "90.16% accuracy on MLP with one hidden layer with 500 neurons. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
