{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEXFP1ph7lwF",
        "outputId": "d3eeabf4-096c-4ab4-86ea-e8f847710208"
      },
      "outputs": [],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "w-FY5hlD7ose"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.decomposition import TruncatedSVD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "DcAL403W7tzT",
        "outputId": "e4192134-bf0e-4e6d-e8f8-0a4407ac77e3"
      },
      "outputs": [],
      "source": [
        "text = pd.read_csv(\"IMDB Dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UmC8CvNJ8qGk"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1XY94pq09N7M"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>[one, of, the, other, reviewers, has, mentione...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "      <td>[wonderful, little, production, br, br, the, f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "      <td>[thought, this, was, wonderful, way, to, spend...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[basically, there, family, where, little, boy,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "      <td>[petter, mattei, love, in, the, time, of, mone...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment  \\\n",
              "0  One of the other reviewers has mentioned that ...  positive   \n",
              "1  A wonderful little production. <br /><br />The...  positive   \n",
              "2  I thought this was a wonderful way to spend ti...  positive   \n",
              "3  Basically there's a family where a little boy ...  negative   \n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
              "\n",
              "                                        review_clean  \n",
              "0  [one, of, the, other, reviewers, has, mentione...  \n",
              "1  [wonderful, little, production, br, br, the, f...  \n",
              "2  [thought, this, was, wonderful, way, to, spend...  \n",
              "3  [basically, there, family, where, little, boy,...  \n",
              "4  [petter, mattei, love, in, the, time, of, mone...  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text[\"review_clean\"] = text[\"review\"].apply(lambda x: gensim.utils.simple_preprocess(x))\n",
        "text.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mFa6JLi89e8z"
      },
      "outputs": [],
      "source": [
        "clean_text = text[[\"review_clean\"]]\n",
        "labels = text[\"sentiment\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0wfQ884eLuh7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "71moLCX6I5q9"
      },
      "outputs": [],
      "source": [
        "corpus = []\n",
        "for review in clean_text[\"review_clean\"]:\n",
        "  corpus.append(\" \".join(review))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vJ0o4p0eLE3b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fqW0SzBVLtIo"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\bmaj3\\AppData\\Local\\Temp\\ipykernel_7360\\1042297266.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  clean_text[\"corpus\"] = corpus\n"
          ]
        }
      ],
      "source": [
        "clean_text[\"corpus\"] = corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uTbQx2pbL_Ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_ULo3isJMB1f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_clean</th>\n",
              "      <th>corpus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[one, of, the, other, reviewers, has, mentione...</td>\n",
              "      <td>one of the other reviewers has mentioned that ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[wonderful, little, production, br, br, the, f...</td>\n",
              "      <td>wonderful little production br br the filming ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[thought, this, was, wonderful, way, to, spend...</td>\n",
              "      <td>thought this was wonderful way to spend time o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[basically, there, family, where, little, boy,...</td>\n",
              "      <td>basically there family where little boy jake t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[petter, mattei, love, in, the, time, of, mone...</td>\n",
              "      <td>petter mattei love in the time of money is vis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>[thought, this, movie, did, down, right, good,...</td>\n",
              "      <td>thought this movie did down right good job it ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>[bad, plot, bad, dialogue, bad, acting, idioti...</td>\n",
              "      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>[am, catholic, taught, in, parochial, elementa...</td>\n",
              "      <td>am catholic taught in parochial elementary sch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>[going, to, have, to, disagree, with, the, pre...</td>\n",
              "      <td>going to have to disagree with the previous co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>[no, one, expects, the, star, trek, movies, to...</td>\n",
              "      <td>no one expects the star trek movies to be high...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            review_clean  \\\n",
              "0      [one, of, the, other, reviewers, has, mentione...   \n",
              "1      [wonderful, little, production, br, br, the, f...   \n",
              "2      [thought, this, was, wonderful, way, to, spend...   \n",
              "3      [basically, there, family, where, little, boy,...   \n",
              "4      [petter, mattei, love, in, the, time, of, mone...   \n",
              "...                                                  ...   \n",
              "49995  [thought, this, movie, did, down, right, good,...   \n",
              "49996  [bad, plot, bad, dialogue, bad, acting, idioti...   \n",
              "49997  [am, catholic, taught, in, parochial, elementa...   \n",
              "49998  [going, to, have, to, disagree, with, the, pre...   \n",
              "49999  [no, one, expects, the, star, trek, movies, to...   \n",
              "\n",
              "                                                  corpus  \n",
              "0      one of the other reviewers has mentioned that ...  \n",
              "1      wonderful little production br br the filming ...  \n",
              "2      thought this was wonderful way to spend time o...  \n",
              "3      basically there family where little boy jake t...  \n",
              "4      petter mattei love in the time of money is vis...  \n",
              "...                                                  ...  \n",
              "49995  thought this movie did down right good job it ...  \n",
              "49996  bad plot bad dialogue bad acting idiotic direc...  \n",
              "49997  am catholic taught in parochial elementary sch...  \n",
              "49998  going to have to disagree with the previous co...  \n",
              "49999  no one expects the star trek movies to be high...  \n",
              "\n",
              "[50000 rows x 2 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ml7DQjhYBf7k"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(clean_text, \n",
        "                                                    labels, \n",
        "                                                    test_size=0.30, \n",
        "                                                    random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sVgKX5y3KNlD"
      },
      "outputs": [],
      "source": [
        "tfidf_vect = TfidfVectorizer()\n",
        "X_train_tfidf = tfidf_vect.fit_transform(X_train[\"corpus\"])\n",
        "X_test_tfidf = tfidf_vect.transform(X_test[\"corpus\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2ryaYZeZLZG"
      },
      "outputs": [],
      "source": [
        "svd = TruncatedSVD(n_components = 10000, n_iter=7, random_state=42)\n",
        "X_train_reduced = svd.fit_transform(X_train_tfidf)\n",
        "X_test_reduced = svd.transform(X_test_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sum(svd.explained_variance_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5000 SVD components takes 67 minutes and 34 seconds "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "id": "0nROyGJRPWLb",
        "outputId": "892110c4-afff-4da8-b2f0-a923f50693f2"
      },
      "outputs": [],
      "source": [
        "X_train_tfidf_df = pd.DataFrame(X_train_reduced, index = X_train.index, columns = [i for i in range(101, 5101)])\n",
        "X_test_tfidf_df = pd.DataFrame(X_test_reduced, index = X_test.index, columns = [i for i in range(101, 5101)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJ4pJR0KBtcZ"
      },
      "outputs": [],
      "source": [
        "w2v_model = gensim.models.Word2Vec(X_train[\"review_clean\"],\n",
        "                                   vector_size=100,\n",
        "                                   window=5,\n",
        "                                   min_count=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1oxYI9VB4R7"
      },
      "outputs": [],
      "source": [
        "words = set(w2v_model.wv.index_to_key)\n",
        "X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words]) for ls in X_train[\"review_clean\"]], dtype = \"object\")\n",
        "X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words]) for ls in X_test[\"review_clean\"]], dtype = \"object\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yATe902ELz6"
      },
      "outputs": [],
      "source": [
        "# Compute sentence vectors by averaging the word vectors for the words contained in the sentence\n",
        "X_train_vect_avg = []\n",
        "for v in X_train_vect:\n",
        "    if v.size:\n",
        "        X_train_vect_avg.append(v.mean(axis=0))\n",
        "    else:\n",
        "        X_train_vect_avg.append(np.zeros(100, dtype=float))\n",
        "        \n",
        "X_test_vect_avg = []\n",
        "for v in X_test_vect:\n",
        "    if v.size:\n",
        "        X_test_vect_avg.append(v.mean(axis=0))\n",
        "    else:\n",
        "        X_test_vect_avg.append(np.zeros(100, dtype=float))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xFDc8hFI0T8"
      },
      "outputs": [],
      "source": [
        "X_train_df = pd.DataFrame(X_train_vect_avg, index = X_train.index)\n",
        "X_test_df = pd.DataFrame(X_test_vect_avg, index = X_test.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = pd.concat([X_train_df, X_train_tfidf_df], axis = 1)\n",
        "X_test = pd.concat([X_test_df, X_test_tfidf_df], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#X_train.to_csv(\"X_train.csv\",index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#X_test.to_csv(\"X_test.csv\",index = False)\n",
        "#y_train.to_csv(\"y_train.csv\", index = False)\n",
        "#y_test.to_csv(\"y_test.csv\",index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_2UWW68E52r"
      },
      "outputs": [],
      "source": [
        "clf = SVC()\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kh7drxvfG6Bb"
      },
      "outputs": [],
      "source": [
        "y_pred = clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6MfNK8NIVkQ",
        "outputId": "d09369a9-4b54-4bfe-c828-deadfd9dfaee"
      },
      "outputs": [],
      "source": [
        "print(accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SL2iN3FBIutm"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = pd.read_csv(\"X_train.csv\")\n",
        "X_test = pd.read_csv(\"X_test.csv\")\n",
        "y_train = pd.read_csv(\"y_train.csv\")\n",
        "y_test = pd.read_csv(\"y_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlp_clf = MLPClassifier(random_state=1, \n",
        "                        max_iter=300, \n",
        "                        verbose = True, \n",
        "                        learning_rate = \"adaptive\",\n",
        "                        hidden_layer_sizes= (500,))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\bmaj3\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.40474168\n",
            "Iteration 2, loss = 0.24661517\n",
            "Iteration 3, loss = 0.20853547\n",
            "Iteration 4, loss = 0.19124095\n",
            "Iteration 5, loss = 0.17913470\n",
            "Iteration 6, loss = 0.17258685\n",
            "Iteration 7, loss = 0.15931708\n",
            "Iteration 8, loss = 0.14822907\n",
            "Iteration 9, loss = 0.13690262\n",
            "Iteration 10, loss = 0.12244667\n",
            "Iteration 11, loss = 0.11046435\n",
            "Iteration 12, loss = 0.09495594\n",
            "Iteration 13, loss = 0.07900742\n",
            "Iteration 14, loss = 0.06443615\n",
            "Iteration 15, loss = 0.05225513\n",
            "Iteration 16, loss = 0.04103373\n",
            "Iteration 17, loss = 0.03338778\n",
            "Iteration 18, loss = 0.02623813\n",
            "Iteration 19, loss = 0.02062841\n",
            "Iteration 20, loss = 0.01708508\n",
            "Iteration 21, loss = 0.01437299\n",
            "Iteration 22, loss = 0.01240667\n",
            "Iteration 23, loss = 0.01106241\n",
            "Iteration 24, loss = 0.01000019\n",
            "Iteration 25, loss = 0.00915337\n",
            "Iteration 26, loss = 0.00844007\n",
            "Iteration 27, loss = 0.00798715\n",
            "Iteration 28, loss = 0.00755547\n",
            "Iteration 29, loss = 0.00716364\n",
            "Iteration 30, loss = 0.00688550\n",
            "Iteration 31, loss = 0.00662502\n",
            "Iteration 32, loss = 0.00643417\n",
            "Iteration 33, loss = 0.00621508\n",
            "Iteration 34, loss = 0.00603065\n",
            "Iteration 35, loss = 0.00587241\n",
            "Iteration 36, loss = 0.00574166\n",
            "Iteration 37, loss = 0.00581300\n",
            "Iteration 38, loss = 0.00665123\n",
            "Iteration 39, loss = 0.00650295\n",
            "Iteration 40, loss = 0.04246585\n",
            "Iteration 41, loss = 0.01396573\n",
            "Iteration 42, loss = 0.00767030\n",
            "Iteration 43, loss = 0.00677372\n",
            "Iteration 44, loss = 0.00644303\n",
            "Iteration 45, loss = 0.00621900\n",
            "Iteration 46, loss = 0.00603593\n",
            "Iteration 47, loss = 0.00588673\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLPClassifier(hidden_layer_sizes=(500,), learning_rate='adaptive', max_iter=300,\n",
              "              random_state=1, verbose=True)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlp_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 500 neurons 1 layer took 22 minutes 39 seconds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_predict = mlp_clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8930666666666667\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_score(y_test, y_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlp_clf.n_layers_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
